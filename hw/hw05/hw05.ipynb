{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8015dc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw05.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738ad94d-3abe-47ef-affe-b615d24d8dee",
   "metadata": {},
   "source": [
    "<img style=\"display: block; margin-left: auto; margin-right: auto\" src=\"./ccsf-logo.png\" width=\"250rem;\" alt=\"The CCSF black and white logo\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d2f744-1354-4b2c-8c1f-eb5b158f195f",
   "metadata": {},
   "source": [
    "# Homework 5: Iteration and Chance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ab4605-7efd-4cdb-8615-d0dbd275fc8f",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* [Sections 9.0 - 9.3](https://inferentialthinking.com/chapters/09/Randomness.html)\n",
    "* [Chapter 10](https://inferentialthinking.com/chapters/10/Sampling_and_Empirical_Distributions.html)\n",
    "* [`datascience` Documentation](https://datascience.readthedocs.io/)\n",
    "* [Python Quick Reference](https://ccsf-math-108.github.io/materials-fa23/resources/quick_reference.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fec9ccf-0760-4515-b8f8-e370c3226df6",
   "metadata": {},
   "source": [
    "## Assignment Reminders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57a42a2-ddcd-411c-84fa-bd1019128915",
   "metadata": {},
   "source": [
    "- Make sure to run the code cell at the top of this notebook that starts with `# Initialize Otter` to load the auto-grader.\n",
    "- For all tasks indicated with a üîé that you must write explanations and sentences for, provide your answer in the designated space.\n",
    "- Throughout this assignment and all future ones, please be sure to not re-assign variables throughout the notebook! _For example, if you use `max_temperature` in your answer to one question, do not reassign it later on. Otherwise, you will fail tests that you thought you were passing previously!_\n",
    "- We encourage you to discuss this assignment with others but make sure to write and submit your own code. Refer to the syllabus to learn more about how to learn cooperatively.\n",
    "- Unless you are asked otherwise, use the non-interactive visualizations when asked to produce a visualization for a task.\n",
    "- View the related <a href=\"https://ccsf.instructure.com\" target=\"_blank\">Canvas</a> Assignment page for additional details.\n",
    "\n",
    "Run the following code cell to import the tools for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebc20c7-43ab-4215-ab57-8318ebc1d136",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84499d5d-c501-4fc5-9c48-9dd1b0093fb9",
   "metadata": {},
   "source": [
    "## 2023-24 CCSF Football Season"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9067b083-6c87-4e12-b016-23b6dd2f9040",
   "metadata": {},
   "source": [
    "You are going to analyze how well the CCSF football team performed in the 2023-24 season. A football game is divided into four periods, called quarters. The number of points CCSF scored in each quarter (e.g. `CCSF 1Q`), and the number of points their opponent scored in each quarter  (e.g. `Opp 1Q`) are stored in a table called `games`. If the game is tied at the end of the 4th quarter, the game goes into an additional period called overtime.\n",
    "\n",
    "**Notes**:\n",
    "* The 2022-24 season data was collected using the Game Log from [the CCSF Athletics website](https://ccsfathletics.com/sports/fball/2023-24/teams/sanfrancisco?view=gamelog).\n",
    "* The table `games_ful` contains dditional statistics at the right end of the table for your curiosity.\n",
    "* A `nan` value indicates that no data was provided on the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440138f2-0f42-42db-acc7-ce9f73c9e6f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "games_full = Table().read_table(\"ccsf_fb.csv\")\n",
    "games = games_full.select(1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12)\n",
    "games.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82975a5f-c73a-44a6-8672-0eef66826944",
   "metadata": {},
   "source": [
    "Let's start by finding the total points each team scored in a game."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f41c2a-36bd-425d-b845-784267edaa4c",
   "metadata": {},
   "source": [
    "### Task 01 üìç"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583ea917-138c-4e2a-98d9-7224cc5eda6b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Write a function called `sum_scores`.  It should take five arguments, where each argument is the team's quarter or overtime score. It should return the team's total score for that game.\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efae119-dcab-4a5e-b838-e3d4e19f73f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sum_scores(...):\n",
    "    \"\"\"Returns the total score calculated by adding up the score of each quarter and the overtime\"\"\"\n",
    "    ...\n",
    "\n",
    "sum_scores(14, 7, 3, 0, 3) #DO NOT CHANGE THIS LINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed217082",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task_01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49f93a0-51df-4089-a2d2-d9d011011328",
   "metadata": {},
   "source": [
    "### Task 02 üìç"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5d75a1-7b9d-47f7-91b5-fa7972332b32",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Create a new table `final_scores` with three columns in this *specific* order: `Opponent`, `CCSF Score`, `Opponent Score`. You will have to create the `CCSF Score` and `Opponent Score` columns. Use the function `sum_scores` you just defined in the previous question for this problem.\n",
    "\n",
    "*Hint:* If you want to apply a function that takes in multiple arguments, you can pass multiple column names as arguments in `tbl.apply()`. The column values will be passed into the corresponding arguments of the function. Take a look at the python reference for syntax.\n",
    "\n",
    "*Tip:* If you‚Äôre running into issues creating final_scores, check that `ccsf_scores` and `opponent_scores` output what you want. Also, you will more than likely want to create more steps/intermediate variables.\n",
    "\n",
    "\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee6c92b-7195-497e-a75d-b10ce252d6c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_scores = ...\n",
    "final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62eb5845",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task_02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e8fc62-b494-407f-85ba-6698cd4e1fe0",
   "metadata": {},
   "source": [
    "We can get specific row objects from a table. You can use `tbl.row(n)` to get the `(n+1)`th row of a table. `row.item(\"column_name\")` will allow you to select the element that corresponds to `column_name` in a particular row. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b506bb61-1f5a-4d38-b846-b46fb0122827",
   "metadata": {
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Just run this cell\n",
    "games.row(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f3a280-6f7a-420f-a342-f972c1c37cfb",
   "metadata": {
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Just run this cell\n",
    "games.row(10).item(\"CCSF 4Q\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae9b8a0-2939-4b8b-88f8-37510a11d9a8",
   "metadata": {},
   "source": [
    "### Task 03 üìç"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b6388c-baef-4d8e-9e83-bb1a0a1af8fd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We want to see for a particular game whether or not CCSF won. Write a function called `did_ccsf_win`.  It should take one argument: a **row object** from the `final_scores` table. It should return either `True` if CCSF's score was greater than the Opponent's score, and `False` otherwise.\n",
    "\n",
    "*Note 1*: \"Row object\" means a row from the table extracted (behind the scenes) using `tbl.row(index)` that contains all the data for that specific row. It is **not** the index of a row. Do not try and call `final_scores.row(row)` inside of the function.\n",
    "\n",
    "*Note 2*: If you're still confused by row objects, try printing out `final_scores.row(1)` in a new cell to visually see what it looks like! This piece of code is pulling out the row object located at index 1 of the `final_scores` table and returning it. When you display it in a cell, you'll see that it is not located within a table, but is instead a standalone row object!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d56c716-bf45-44ab-9fc6-636e3e7e8dd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ...(row):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4eddbaa",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task_03\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7031d9cf-15a4-415e-ae7c-5463f1e992fe",
   "metadata": {},
   "source": [
    "### Task 04 üìç"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc20fa6b-de15-4cb4-af99-6d07f332322e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Unfortunately, CCSF did not win against every opponent during the 2023-24 season. Using the `final_scores` table, assign `results` to an array of `True` and `False` values that correspond to whether or not CCSF won. Add the `results` array to the `final_scores` table, and assign this to `final_scores_with_results`. Then, respectively assign the number of wins and losses CCSF had to `ccsf_wins` and `ccsf_losses`.\n",
    "\n",
    "*Hint*: When you only pass a function name and no column labels through `tbl.apply()`, the function gets applied to every row in `tbl`\n",
    "\n",
    "\n",
    "\n",
    "_Points:_ 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4152664e-d4ce-479b-8e1b-78b3cac7be1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = ...\n",
    "final_scores_with_results = ...\n",
    "ccsf_wins = ...\n",
    "ccsf_losses = ...\n",
    "\n",
    "# Don't delete or edit the following line:\n",
    "print(f\"In the 2023-24 Season, CCSF Football won {ccsf_wins} games and lost {ccsf_losses} games. Go RAMS!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103dac23",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task_04\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d324c79-6be5-4ec9-af89-ace5f71daae9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Task 05 üìç"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7accdf-4849-4ccc-ba36-eab8ccf395be",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Sometimes in football, the two teams are equally matched and the game is quite close. Other times, it is a blowout, where the winning team wins by a large margin of victory. Let's define a **big win** to be a game in which the winning team won by more than 10 points. \n",
    "\n",
    "Create a function called `is_big_win`.\n",
    "* The function should accept a single row (`datascience.tables.Row` data type) from a table like the `final_scores` table.\n",
    "* The function should output `True` if CCSF won by **more than** 10 points. Otherwise, it should return `False`.\n",
    "\n",
    "Test your function on the first row of the table. `final_scores.row(0)` should be the row object `Row(Opponent='Santa Rosa', CCSF Score=58, Opponent Score=14)`. Since CCSF's score is more than 10 points larger than Santa Rosa's score, then `is_big_win` applied to that row should output `True`.\n",
    "\n",
    "_Points:_ 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf632c65-9bec-4869-9e4a-d303bc2676ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "# Test your function \n",
    "row1 = final_scores.row(0)\n",
    "is_big_win(row1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e792e06",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task_05\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eac74ac-6fda-4cfd-91f4-d608424ca8d7",
   "metadata": {},
   "source": [
    "### Task 06 üìç"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d741c94-cdf7-42ac-929a-298f0d709324",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Use your `final_scores` table with your `is_big_win` function to assign `big_wins` to an array of team names that CCSF had big wins against during the 2023-24 football season.\n",
    "\n",
    "_Points:_ 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8edfb91-9cc8-4669-a245-f458492c4699",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "big_wins = ...\n",
    "\n",
    "for row_index ...\n",
    "    row = ...\n",
    "    opponent = ...\n",
    "    if ...:\n",
    "        big_wins = np.append(big_wins, ...)\n",
    "\n",
    "big_wins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd53945",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task_06\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbbab36-1992-48c0-b2df-01468bccd36b",
   "metadata": {},
   "source": [
    "## Roulette"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cf3e68-8494-4313-9de1-b36e3edaa4ea",
   "metadata": {},
   "source": [
    "### Chance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6141ead-594d-4d3e-823f-5923f5e5bde5",
   "metadata": {},
   "source": [
    "A Nevada roulette wheel has 38 pockets and a small ball that rests on the wheel. When the wheel is spun, the ball comes to rest in one of the 38 pockets. That pocket is declared the winner. \n",
    "\n",
    "The pockets are labeled 0, 00, 1, 2, 3, 4, ... , 36. Pockets 0 and 00 are green, and the other pockets are alternately red and black. The table `wheel` is a representation of a Nevada roulette wheel. **Note that *both* columns consist of strings.** Below is an example of a roulette wheel!\n",
    "\n",
    "<img src=\"./roulette_wheel.jpeg\" alt=\"roulette wheel\" width=\"330px\">\n",
    "\n",
    "Run the cell below to load the `wheel` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1c9290-57c9-4fcb-a760-2dc3f239464a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wheel = Table.read_table('roulette_wheel.csv', dtype=str)\n",
    "wheel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d5c3c1-beea-440c-b91d-7cade7d82fa7",
   "metadata": {},
   "source": [
    "Before you do the following tasks, make sure you understand the logic behind all the examples in [Section 9.5](https://inferentialthinking.com/chapters/09/5/Finding_Probabilities.html). \n",
    "\n",
    "Good ways to approach probability calculations include:\n",
    "\n",
    "- Thinking one trial at a time: What does the first one have to be? Then what does the next one have to be?\n",
    "- Breaking up the event into distinct ways in which it can happen.\n",
    "- Seeing if it is easier to find the chance that the event does not happen.\n",
    "\n",
    "On each spin of a roulette wheel, all 38 pockets are equally likely to be the winner regardless of the results of other spins. Among the 38 pockets, 18 are red, 18 black, and 2 green."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece6916d-4e26-43dd-aeca-1d4c13528867",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Task 07 üìç"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e28515-49dc-4385-aff7-21afabdadc2e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The winning pocket is black on all of the first three spins.\n",
    "\n",
    "_Provide an expression that Python evaluates to the chance of the event described._\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cb750c-73f9-4acb-a628-07a7c5a4389b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "first_three_black = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827901f0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task_07\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63b4344-3069-4888-9e41-f57e5bf0c850",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Task 08 üìç"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02aaed34-4277-4ae7-bbcf-53fd968a9e39",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The color green never wins in the first 10 spins.\n",
    "\n",
    "_Provide an expression that Python evaluates to the chance of the event described._\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c872f63b-2f4d-4b12-9a49-e2ea0d25fd44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "no_green = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c33cf2f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task_08\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c75b1d-a00d-4657-ac0c-e99a5977d24c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Task 09 üìç"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e8fc4f-1abf-4851-bb9e-68abd0f732cb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The color green wins **at least** once on the first 10 spins.\n",
    "\n",
    "_Provide an expression that Python evaluates to the chance of the event described._\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea678a72-2db4-42d1-8dc4-0b4317651a1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "at_least_one_green = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9bf93a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task_09\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3458e790-7ec1-4ba5-ba74-6f21ebea2e5d",
   "metadata": {},
   "source": [
    "### Comparing Chances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e67b0c7-bf73-4358-9d2b-8bc2ffa6f481",
   "metadata": {},
   "source": [
    "In each of the following two tasks, two events A and B are described. Choose from one of the following three options and set each answer variable to a single integer:\n",
    "\n",
    "1. Event A is more likely than Event B\n",
    "2. Event B is more likely than Event A\n",
    "3. The two events have the same chance.\n",
    "\n",
    "You should be able to make the choices **without calculation**. Good ways to approach this exercise include imagining carrying out the chance experiments yourself, one trial at a time, and by thinking about the [law of averages](https://inferentialthinking.com/chapters/10/1/Empirical_Distributions.html#the-law-of-averages)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e71723-b26f-44b5-b5a6-60a3af0fb1a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Task 10 üìç"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda1b017-8b4f-4c3e-ba6d-a13950b20d83",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "A child picks four times at random from a box that has four toy animals: a bear, an elephant, a giraffe, and a kangaroo.\n",
    "\n",
    "- Event A: all four different animals are picked, assuming the child picks without replacement\n",
    "- Event B: all four different animals are picked, assuming the child picks with replacement\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfb9231-0f86-42f5-aea7-b2c9740cd567",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "toys_option = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176453ca",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task_10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0cb3ab-fa56-432f-9d14-37821a0fed07",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Task 11 üìç"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0cd088-9271-4430-bb07-7c9000efa2da",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "In a lottery, two numbers are drawn at random without replacement from the integers 1 through 1000.\n",
    "\n",
    "- Event A: The number 8 is picked on both draws\n",
    "- Event B: The same number is picked on both draws\n",
    "\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2933f3c9-202d-4b3e-b237-c9ec02c8fe6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lottery_option = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d73d065",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task_11\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee82203-af2a-4664-b54b-78cc06c76661",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Submit your Homework to Canvas\n",
    "\n",
    "Once you have finished working on the homework tasks, prepare to submit your work in Canvas by completing the following steps.\n",
    "\n",
    "1. In the related Canvas Assignment page, check the rubric to know how you will be scored for this assignment.\n",
    "2. Double-check that you have run the code cell near the end of the notebook that contains the command `\"grader.check_all()\"`. This command will run all of the run tests on all your responses to the auto-graded tasks marked with üìç.\n",
    "3. Double-check your responses to the manually graded tasks marked with üìçüîé.\n",
    "3. Select the menu item \"File\" and \"Save Notebook\" in the notebook's Toolbar to save your work and create a specific checkpoint in the notebook's work history.\n",
    "4. Select the menu items \"File\", \"Download\" in the notebook's Toolbar to download the notebook (.ipynb) file. \n",
    "5. In the related Canvas Assignment page, click Start Assignment or New Attempt to upload the downloaded .ipynb file.\n",
    "\n",
    "**Keep in mind that the autograder does not always check for correctness. Sometimes it just checks for the format of your answer, so passing the autograder for a question does not mean you got the answer correct for that question.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6434500d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284913cd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "otter": {
   "OK_FORMAT": true,
   "assignment_name": "hw05_sp24",
   "tests": {
    "task_01": {
     "name": "task_01",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> sum_scores(14, 7, 3, 0, 3) == 27 and sum_scores(2, 3, 6, 1, 0) == 12\nTrue",
         "failure_message": "‚ùå Your function doesn't seem to work correctly with our 4 quarter scores and over time score.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ Your function works with our 4 quarter scores and over time score."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task_02": {
     "name": "task_02",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> final_scores.num_columns == 3\nTrue",
         "failure_message": "‚ùå final_scores does not have the correct number of columns.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ final_scores has the correct number of columns."
        },
        {
         "code": ">>> set(['Opponent', 'CCSF Score', 'Opponent Score']) == set(final_scores.labels)\nTrue",
         "failure_message": "‚ùå final_scores does not have the correct labels.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ final_scores has the correct labels."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task_03": {
     "name": "task_03",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> 'did_ccsf_win' in globals() and callable(did_ccsf_win)\nTrue",
         "failure_message": "‚ùå You didn't create a function called did_ccsf_win.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ You've created a function called did_ccsf_win."
        },
        {
         "code": ">>> did_ccsf_win(final_scores.row(1)) == True\nTrue",
         "failure_message": "‚ùå Your function doesn't that CCSF won against Sacramento City.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ Your function shows that CCSF won against Sacramento City."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task_04": {
     "name": "task_04",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> 0 <= ccsf_wins <= 11\nTrue",
         "failure_message": "‚ùå There were only 13 games, so CCSF won 0, 1, 2, ..., or 11 games.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ ccsf_wins is a possible value"
        },
        {
         "code": ">>> 0 <= ccsf_losses <= 11\nTrue",
         "failure_message": "‚ùå There were only 13 games, so CCSF lost 0, 1, 2, ..., or 11 games.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ ccsf_losses is a possible value"
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task_05": {
     "name": "task_05",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> callable(is_big_win)\nTrue",
         "failure_message": "‚ùå It doesn't seem like you defined a function called is_big_win.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ It seems like you defined a function called is_big_win."
        },
        {
         "code": ">>> is_big_win(final_scores.row(0)) == True\nTrue",
         "failure_message": "‚ùå Your function doesn't produce the correct output for the first row of final_scores.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ Your function produces the correct output for the first row of final_scores."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task_06": {
     "name": "task_06",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(big_wins, np.ndarray)\nTrue",
         "failure_message": "‚ùå big_wins should be a NumPy array.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ big_wins is a NumPy array."
        },
        {
         "code": ">>> type(big_wins.item(0)) == str\nTrue",
         "failure_message": "‚ùå The first item in big_wins is not a string.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ The first item in big_wins is a string."
        },
        {
         "code": ">>> 0 <= len(big_wins) <= 11\nTrue",
         "failure_message": "‚ùå There is not a possible value for the number items in big_wins.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ There is a possible value for the number items in big_wins."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task_07": {
     "name": "task_07",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> 0 <= first_three_black <= 1\nTrue",
         "failure_message": "‚ùå first_three_black should be a numerical value between 0 and 1, inclusive.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ first_three_black is a numerical value between 0 and 1, inclusive."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task_08": {
     "name": "task_08",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> 0 <= no_green <= 1\nTrue",
         "failure_message": "‚ùå no_green should be a numerical value between 0 and 1, inclusive.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ no_green is a numerical value between 0 and 1, inclusive."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task_09": {
     "name": "task_09",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> 0 <= at_least_one_green <= 1\nTrue",
         "failure_message": "‚ùå at_least_one_green should be a numerical value between 0 and 1, inclusive.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ at_least_one_green is a numerical value between 0 and 1, inclusive."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task_10": {
     "name": "task_10",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> toys_option in [1, 2, 3]\nTrue",
         "failure_message": "‚ùå 1, 2, or 3 should be assigned to toys_option.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ This is a possible value for toys_option."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task_11": {
     "name": "task_11",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> lottery_option in [1, 2, 3]\nTrue",
         "failure_message": "‚ùå 1, 2, or 3 should be assigned to lottery_option.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ This is a possible value for lottery_option."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
